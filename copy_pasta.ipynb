{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2103e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of churned customers\n",
    "charterdp = train[train.charter_encoded==1].discipline_percent\n",
    "charterdp.hist()\n",
    "\n",
    "# histogram of non-churned customers\n",
    "non_charterdp = train[train.charter_encoded==0].discipline_percent\n",
    "non_charterdp.hist()\n",
    "\n",
    "mean_a = charterdp.mean()\n",
    "mean_b = non_charterdp.mean()\n",
    "\n",
    "mean_a, mean_b\n",
    "\n",
    "# remember that our confidence level determines our alpha, \n",
    "# which we use to compare to p\n",
    "alpha = 0.05\n",
    "\n",
    "# Mini H0: variances are equal between groups\n",
    "# Ha: variances are inequal between groups\n",
    "# alpha: 0.05\n",
    "stat, pval = stats.levene(charterdp, non_charterdp)\n",
    "\n",
    "pval\n",
    "\n",
    "print('Is p less than alpha? ', pval < alpha)\n",
    "\n",
    "# implications of one-tailed two-sampled t-test:\n",
    "# p will be divided by two because we are only looking at one tail of the curve\n",
    "# we will pay attention to the sign of our t-statistic\n",
    "# t, p = t-test: (group A, group B) ==> comparison of mu_a > mu_b\n",
    "t, p = stats.ttest_ind(charterdp, non_charterdp, equal_var=False)\n",
    "t, p\n",
    "\n",
    "if (t > 0) and ((p / 2) < alpha):\n",
    "    print('We can reject the null hypothesis')\n",
    "else:\n",
    "    print('we fail to reject the null hypothesis')\n",
    "\n",
    "    \n",
    "t, p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline\n",
    "\n",
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "baseline\n",
    "\n",
    "X_train['baseline_prediction'] = 0\n",
    "X_train\n",
    "\n",
    "actual = y_train\n",
    "predictions = X_train.baseline_prediction\n",
    "\n",
    "pd.crosstab(y_train['charter_encoded'], X_train.baseline_prediction)\n",
    "\n",
    "2557/(2557+291)\n",
    "\n",
    "# Creates a boolean array where \"No\" becomes True and \"Yes\" becomes False\n",
    "(y_train == 0)\n",
    "\n",
    "# Takes the .mean() of the boolean array that represents the proportion \n",
    "# that would also match our baseline prediction\n",
    "(y_train == 0).mean() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564bc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decision tree object and specify hyperparams\n",
    "tree = DecisionTreeClassifier(max_depth = 3, random_state=123)\n",
    "\n",
    "tree\n",
    "\n",
    "tree.fit(X_validate, y_validate)\n",
    "\n",
    "# Rudimentary visualization of model structure\n",
    "print(export_text(tree, feature_names=X_validate.columns.tolist()))\n",
    "\n",
    "# Visualize the tree\n",
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree, feature_names=X_validate.columns, class_names=tree.classes_.astype(str))\n",
    "#plt.show()\n",
    "\n",
    "y_pred=tree.predict(X_validate)\n",
    "\n",
    "y_pred_proba = tree.predict_proba(X_validate)\n",
    "\n",
    "tree.predict(X_validate)\n",
    "\n",
    "predictions = tree.predict(X_validate)\n",
    "actual = y_validate\n",
    "\n",
    "confusion_matrix(actual, predictions)\n",
    "\n",
    "pd.crosstab(y_validate['charter_encoded'], tree.predict(X_validate))\n",
    "\n",
    "plot_confusion_matrix(tree, X_validate, y_validate, display_labels=['tradition', 'charter'])\n",
    "\n",
    "\n",
    "print(classification_report(actual, predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57dfa0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d438d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066badbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7859d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad6b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ef624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
